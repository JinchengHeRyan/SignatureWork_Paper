@InProceedings{C2,
    author = "Jones, C.D. and Smith, A.B. and Roberts, E.F.",
    title = "Article Title",
    booktitle = "Proceedings Title",
    organization = "IEEE",
    year = "2003",
    volume = "II",
    pages = "803-806"
}
@inproceedings{li20p_interspeech,
    author = {Tingle Li and Qingjian Lin and Yuanyuan Bao and Ming Li},
    title = {{Atss-Net: Target Speaker Separation via Attention-Based Neural Network}},
    year = 2020,
    booktitle = {Proc. Interspeech 2020},
    pages = {1411--1415},
    doi = {10.21437/Interspeech.2020-1436}
}
@misc{bao2021lightweight,
    title = {Lightweight Dual-channel Target Speaker Separation for Mobile Voice Communication},
    author = {Yuanyuan Bao and Yanze Xu and Na Xu and Wenjing Yang and Hongfeng Li and Shicong Li and Yongtao Jia and Fei Xiang and Jincheng He and Ming Li},
    year = {2021},
    eprint = {2106.02934},
    archivePrefix = {arXiv},
    primaryClass = {cs.SD}
}
@inproceedings{NEURIPS2019_bdbca288,
    author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    url = {https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
    volume = {32},
    year = {2019}
}
@misc{kingma2017adam,
    title = {Adam: A Method for Stochastic Optimization},
    author = {Diederik P. Kingma and Jimmy Ba},
    year = {2017},
    eprint = {1412.6980},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}
@INPROCEEDINGS{fbank,
    author = {Pardede, Hilman F. and Zilvan, Vicky and Krisnandi, Dikdik and Heryana, Ana and Kusumo, R. Budiarianto S.},
    booktitle = {2019 International Conference on Computer, Control, Informatics and its Applications (IC3INA)},
    title = {Generalized Filter-bank Features for Robust Speech Recognition Against Reverberation},
    year = {2019},
    volume = {},
    number = {},
    pages = {19-24},
    doi = {10.1109/IC3INA48034.2019.8949593}
}
@INPROCEEDINGS{librispeech,
    author = {Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
    booktitle = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {Librispeech: An ASR corpus based on public domain audio books},
    year = {2015},
    volume = {},
    number = {},
    pages = {5206-5210},
    doi = {10.1109/ICASSP.2015.7178964}
}
@misc{agarap2019deep,
    title = {Deep Learning using Rectified Linear Units (ReLU)},
    author = {Abien Fred Agarap},
    year = {2019},
    eprint = {1803.08375},
    archivePrefix = {arXiv},
    primaryClass = {cs.NE}
}
@ARTICLE{conv_tasnet,
    author = {Luo, Yi and Mesgarani, Nima},
    journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
    title = {Conv-TasNet: Surpassing Ideal Time–Frequency Magnitude Masking for Speech Separation},
    year = {2019},
    volume = {27},
    number = {8},
    pages = {1256-1266},
    doi = {10.1109/TASLP.2019.2915167}
}
@INPROCEEDINGS{pitch_aware,
    author = {Wang, Ke and Soong, Frank and Xie, Lei},
    booktitle = {ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {A Pitch-aware Approach to Single-channel Speech Separation},
    year = {2019},
    volume = {},
    number = {},
    pages = {296-300},
    doi = {10.1109/ICASSP.2019.8683138}
}
@INPROCEEDINGS{dprnn,
    author = {Luo, Yi and Chen, Zhuo and Yoshioka, Takuya},
    booktitle = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {Dual-Path RNN: Efficient Long Sequence Modeling for Time-Domain Single-Channel Speech Separation},
    year = {2020},
    volume = {},
    number = {},
    pages = {46-50},
    doi = {10.1109/ICASSP40776.2020.9054266}
}
@inproceedings{zhang16d_interspeech,
    author = {Jianshu Zhang and Jian Tang and Li-Rong Dai},
    title = {{RNN-BLSTM Based Multi-Pitch Estimation}},
    year = 2016,
    booktitle = {Proc. Interspeech 2016},
    pages = {1785--1789},
    doi = {10.21437/Interspeech.2016-117}
}
@inproceedings{Talkin2005ARA,
    title = {A Robust Algorithm for Pitch Tracking ( RAPT )},
    author = {David Talkin},
    year = {2005}
}
@INPROCEEDINGS{tasnet,
    author = {Luo, Yi and Mesgarani, Nima},
    booktitle = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {TaSNet: Time-Domain Audio Separation Network for Real-Time, Single-Channel Speech Separation},
    year = {2018},
    volume = {},
    number = {},
    pages = {696-700},
    doi = {10.1109/ICASSP.2018.8462116}
}
@INPROCEEDINGS{rnnoise,
    author = {Valin, Jean-Marc},
    booktitle = {2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)},
    title = {A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement},
    year = {2018},
    volume = {},
    number = {},
    pages = {1-5},
    doi = {10.1109/MMSP.2018.8547084}
}
@INPROCEEDINGS{serial,
    author = {Jiang, Yu and Ge, Meng and Wang, Longbiao and Dang, Jianwu and Honda, Kiyoshi and Zhang, Sulin and Yu, Bo},
    booktitle = {2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
    title = {A Pitch-aware Speaker Extraction Serial Network},
    year = {2020},
    volume = {},
    number = {},
    pages = {616-620},
    doi = {}
}
@ARTICLE{spice,
    author = {Gfeller, Beat and Frank, Christian and Roblek, Dominik and Sharifi, Matt and Tagliasacchi, Marco and Velimirović, Mihajlo},
    journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
    title = {SPICE: Self-Supervised Pitch Estimation},
    year = {2020},
    volume = {28},
    number = {},
    pages = {1118-1128},
    doi = {10.1109/TASLP.2020.2982285}
}
@article{yin,
    author = {de Cheveigné,Alain and Kawahara,Hideki },
    title = {YIN, a fundamental frequency estimator for speech and music},
    journal = {The Journal of the Acoustical Society of America},
    volume = {111},
    number = {4},
    pages = {1917-1930},
    year = {2002},
    doi = {10.1121/1.1458024},
    URL = {
    https://doi.org/10.1121/1.1458024
    },
    eprint = {
    https://doi.org/10.1121/1.1458024
    }
}
@article{swipe,
    author = {Camacho,Arturo and Harris,John G. },
    title = {A sawtooth waveform inspired pitch estimator for speech and music},
    journal = {The Journal of the Acoustical Society of America},
    volume = {124},
    number = {3},
    pages = {1638-1652},
    year = {2008},
    doi = {10.1121/1.2951592},
    URL = {
    https://doi.org/10.1121/1.2951592
    },
    eprint = {
    https://doi.org/10.1121/1.2951592
    }
}
@INPROCEEDINGS{crepe,
    author = {Kim, Jong Wook and Salamon, Justin and Li, Peter and Bello, Juan Pablo},
    booktitle = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {Crepe: A Convolutional Representation for Pitch Estimation},
    year = {2018},
    volume = {},
    number = {},
    pages = {161-165},
    doi = {10.1109/ICASSP.2018.8461329}
}
@inproceedings{voicefilter,
    author = {Quan Wang and Hannah Muckenhirn and Kevin Wilson and Prashant Sridhar and Zelin Wu and John R. Hershey and Rif A. Saurous and Ron J. Weiss and Ye Jia and Ignacio Lopez Moreno},
    title = {{VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking}},
    year = 2019,
    booktitle = {Proc. Interspeech 2019},
    pages = {2728--2732},
    doi = {10.21437/Interspeech.2019-1101},
    url = {http://dx.doi.org/10.21437/Interspeech.2019-1101}
}
@INPROCEEDINGS{time_domain_speaker_ex_net,
    author = {Xu, Chenglin and Rao, Wei and Chng, Eng Siong and Li, Haizhou},
    booktitle = {2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
    title = {Time-Domain Speaker Extraction Network},
    year = {2019},
    volume = {},
    number = {},
    pages = {327-334},
    doi = {10.1109/ASRU46091.2019.9004016}
}
@ARTICLE{spex,
    author = {Xu, Chenglin and Rao, Wei and Chng, Eng Siong and Li, Haizhou},
    journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
    title = {SpEx: Multi-Scale Time Domain Speaker Extraction Network},
    year = {2020},
    volume = {28},
    number = {},
    pages = {1370-1384},
    doi = {10.1109/TASLP.2020.2987429}
}
@inproceedings{spex+,
    author = {Meng Ge and Chenglin Xu and Longbiao Wang and Eng Siong Chng and Jianwu Dang and Haizhou Li},
    title = {{SpEx+: A Complete Time Domain Speaker Extraction Network}},
    year = 2020,
    booktitle = {Proc. Interspeech 2020},
    pages = {1406--1410},
}
@INPROCEEDINGS{speakerfilter,
    author = {He, Shulin and Li, Hao and Zhang, Xueliang},
    booktitle = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {Speakerfilter: Deep Learning-Based Target Speaker Extraction Using Anchor Speech},
    year = {2020},
    volume = {},
    number = {},
    pages = {376-380},
    doi = {10.1109/ICASSP40776.2020.9054222}
}
@misc{speakerfilter_pro,
    title = {Speakerfilter-Pro: an improved target speaker extractor combines the time domain and frequency domain},
    author = {Shulin He and Hao Li and Xueliang Zhang},
    year = {2020},
    eprint = {2010.13053},
    archivePrefix = {arXiv},
    primaryClass = {cs.SD}
}
@ARTICLE{speakerBeam,
    author = {Žmolíková, Kateřina and Delcroix, Marc and Kinoshita, Keisuke and Ochiai, Tsubasa and Nakatani, Tomohiro and Burget, Lukáš and Černocký, Jan},
    journal = {IEEE Journal of Selected Topics in Signal Processing},
    title = {SpeakerBeam: Speaker Aware Neural Network for Target Speaker Extraction in Speech Mixtures},
    year = {2019},
    volume = {13},
    number = {4},
    pages = {800-814},
    doi = {10.1109/JSTSP.2019.2922820}
}
@INPROCEEDINGS{compact_speakerbeam,
    author = {Delcroix, Marc and Zmolikova, Katerina and Ochiai, Tsubasa and Kinoshita, Keisuke and Araki, Shoko and Nakatani, Tomohiro},
    booktitle = {ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {Compact Network for Speakerbeam Target Speaker Extraction},
    year = {2019},
    volume = {},
    number = {},
    pages = {6965-6969},
    doi = {10.1109/ICASSP.2019.8683087}
}
@ARTICLE{performance_measurement,
    author = {Vincent, E. and Gribonval, R. and Fevotte, C.},
    journal = {IEEE Transactions on Audio, Speech, and Language Processing},
    title = {Performance measurement in blind audio source separation},
    year = {2006},
    volume = {14},
    number = {4},
    pages = {1462-1469},
    doi = {10.1109/TSA.2005.858005} }
@article{i-vector,
    title = {I-vector Extraction for Speaker Recognition Based on Dimensionality Reduction},
    journal = {Procedia Computer Science},
    volume = {126},
    pages = {1534-1540},
    year = {2018},
    issn = {1877-0509},
    doi = {https://doi.org/10.1016/j.procs.2018.08.126},
    url = {https://www.sciencedirect.com/science/article/pii/S1877050918314042},
    author = {Noor Salwani Ibrahim and Dzati Athiar Ramli},
    keywords = {Bob Spear toolbox, I-vectors, Dimensionality Reduction, UBM size, Frog Identification},
    abstract = {In the domain of speaker recognition, many methods have been proposed over time. The technology for automatic speaker recognition has now reached a good level of performance but there is still need of improvement. In this paper, a new low-dimensional speaker- and channel-dependent space is defined using a simple factor analysis also known as i-vector. This space is named the total variability space because it models both speaker and channel variabilities. The i-vector subspace modelling is one of the recent methods that have become the state of the art technique in this domain. This method largely provides the benefit of modelling both the intra-domain and inter-domain variabilities into the same low dimensional space. In this study, 2656 syllables bio-acoustic signals from 55 species of frog taken from Intelligent Biometric Group, USM database are used for frog identification system. Parameters of the system are initially tuned such as Universal Background Model (UBM) size (32, 64 and 128 Gaussians) and i-vector dimensionality (100, 200 and 400 dimensions). To the end, we assess the effect of the parameter tuned and record the computation time. We observed that, the accuracy for smaller UBM size and higher i-vector dimensionality outperforms others with result of 91.11% is achieved. From this research, it can be concluded that UBM size and i-vector dimensionality effect the accuracy of frog identification based on i-vector.}
}
@misc{deep_speaker,
    doi = {10.48550/ARXIV.1705.02304},
    url = {https://arxiv.org/abs/1705.02304},
    author = {Li, Chao and Ma, Xiaokong and Jiang, Bing and Li, Xiangang and Zhang, Xuewei and Liu, Xiao and Cao, Ying and Kannan, Ajay and Zhu, Zhenyao},
    keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {Deep Speaker: an End-to-End Neural Speaker Embedding System},
    publisher = {arXiv},
    year = {2017},
    copyright = {arXiv.org perpetual, non-exclusive license}
}
@INPROCEEDINGS{x-vector,
    author = {Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
    booktitle = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {X-Vectors: Robust DNN Embeddings for Speaker Recognition},
    year = {2018},
    volume = {},
    number = {},
    pages = {5329-5333},
    doi = {10.1109/ICASSP.2018.8461375} }
@INPROCEEDINGS{d-vector,
    author = {Variani, Ehsan and Lei, Xin and McDermott, Erik and Moreno, Ignacio Lopez and Gonzalez-Dominguez, Javier},
    booktitle = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {Deep neural networks for small footprint text-dependent speaker verification},
    year = {2014},
    volume = {},
    number = {},
    pages = {4052-4056},
    doi = {10.1109/ICASSP.2014.6854363} }
@misc{s-vector,
    doi = {10.48550/ARXIV.2008.04659},
    url = {https://arxiv.org/abs/2008.04659},
    author = {Mary, N J Metilda Sagaya and Umesh, S and Katta, Sandesh V},
    keywords = {Audio and Speech Processing (eess.AS), Sound (cs.SD), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {S-vectors and TESA: Speaker Embeddings and a Speaker Authenticator Based on Transformer Encoder},
    publisher = {arXiv},
    year = {2020},
    copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{attention,
    doi = {10.48550/ARXIV.1706.03762},
    url = {https://arxiv.org/abs/1706.03762},
    author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
    keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {Attention Is All You Need},
    publisher = {arXiv},
    year = {2017},
    copyright = {arXiv.org perpetual, non-exclusive license}
}
@INPROCEEDINGS{deep_clustering,
    author = {Hershey, John R. and Chen, Zhuo and Le Roux, Jonathan and Watanabe, Shinji},
    booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {Deep clustering: Discriminative embeddings for segmentation and separation},
    year = {2016},
    volume = {},
    number = {},
    pages = {31-35},
    doi = {10.1109/ICASSP.2016.7471631} }
@INPROCEEDINGS{PIT,
    author = {Yu, Dong and Kolbæk, Morten and Tan, Zheng-Hua and Jensen, Jesper},
    booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    title = {Permutation invariant training of deep models for speaker-independent multi-talker speech separation},
    year = {2017},
    volume = {},
    number = {},
    pages = {241-245},
    doi = {10.1109/ICASSP.2017.7952154} }
